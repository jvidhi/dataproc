{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4ffa12a-a895-4145-9f65-6ff36f29db99",
   "metadata": {},
   "source": [
    "# Sample using Python SDK for Dataproc Serverless Spark\n",
    "This notebook can be run in Vertex AI Workbench, User Managed Notebooks with a plain Python kernel</br>\n",
    "Docs: https://cloud.google.com/python/docs/reference/dataproc/latest/google.cloud.dataproc_v1.types.Batch <br>\n",
    "BQ Connector jar versions: https://github.com/GoogleCloudDataproc/spark-bigquery-connector <br>\n",
    "Dataproc Serverless Spark runtime versions: https://cloud.google.com/dataproc-serverless/docs/concepts/versions/spark-runtime-versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75d89fd4-ecd9-4e95-a9a3-9f8475c23543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 -m pip install google-cloud-dataproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aaacf3ed-215c-4f11-82fa-a17b146c3fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import dataproc_v1 as dataproc\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "560ed17a-3336-406b-9aaa-108c0c4a6283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID:  gcp-scalable-ml-workshop\n",
      "Project Number:  569379262211\n",
      "UMSA FQN:  s8s-lab-sa@gcp-scalable-ml-workshop.iam.gserviceaccount.com\n",
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "# 1. Get project and UMSA details dynamically\n",
    "project_id_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "PROJECT_ID = project_id_output[0]\n",
    "print(\"Project ID: \", PROJECT_ID)\n",
    "    \n",
    "    \n",
    "project_nbr_output = !gcloud projects describe $PROJECT_ID --format='value(projectNumber)'\n",
    "PROJECT_NBR = project_nbr_output[0]\n",
    "print(\"Project Number: \", PROJECT_NBR)\n",
    "    \n",
    "umsa_output = !gcloud config list account --format \"value(core.account)\"\n",
    "UMSA_FQN = umsa_output[0]\n",
    "print(\"UMSA FQN: \", UMSA_FQN)\n",
    "\n",
    "!gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74444a3b-9132-4f11-a8ed-45310c87b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Variables\n",
    "GCP_REGION = \"us-central1\" \n",
    "NETWORK_TAG = \"dataproc\"\n",
    "BQ_CONNECTOR_COORDS = \"2.12:0.25.2\"\n",
    "CUSTOM_CONTAINER_IMAGE_TAG = \"1.0.0\"\n",
    "SERVERLESS_SPARK_RUNTIME_VERSION = \"1.0.23\"\n",
    "CODE_BUCKET=f\"s8s_code_bucket-{PROJECT_NBR}\"\n",
    "SPARK_SERVERLESS_SUBNET=\"spark-snet\"\n",
    "DPMS_NAME=f\"s8s-dpms-{PROJECT_NBR}\"\n",
    "PERSISTENT_HISTORY_SERVER_NM=f\"s8s-sphs-{PROJECT_NBR}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a843306-54b2-4f3b-a1ba-b2c679bab7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer-churn-model-preprocessing-4243706688\n"
     ]
    }
   ],
   "source": [
    "# Generate a unique batch ID\n",
    "randomizerCharLength = 10 \n",
    "PIPELINE_ID = ''.join(random.choices(string.digits, k = randomizerCharLength))\n",
    "BATCH_ID=f\"customer-churn-model-preprocessing-{PIPELINE_ID}\"\n",
    "print(BATCH_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "396450c2-6990-4c9b-96f4-a4fcd4e03ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create a client\n",
    "client = dataproc.BatchControllerClient(\n",
    "    client_options={\n",
    "                \"api_endpoint\": f\"{GCP_REGION}-dataproc.googleapis.com:443\"\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86eb3fe2-b6fc-4adc-b7ce-f1782ea112d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Initialize request argument(s)\n",
    "batch = dataproc.Batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fbeaa06-d2e4-457f-886a-fdad094aaa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. App specifics\n",
    "# ....\n",
    "# Main python file\n",
    "batch.pyspark_batch.main_python_file_uri = f\"gs://{CODE_BUCKET}/pyspark/preprocessing.py\"\n",
    "# Dependenices\n",
    "batch.pyspark_batch.python_file_uris = [f\"gs://{CODE_BUCKET}/pyspark/common_utils.py\"]\n",
    "\n",
    "# Jars (optional)\n",
    "#batch.pyspark_batch.jar_file_uris = f\"gs://{CODE_BUCKET}/jars/\"\n",
    "# Files (optional)\n",
    "#batch.pyspark_batch.file_uris = f\"gs://{CODE_BUCKET}/code/files/\"\n",
    "# Archives (optional)\n",
    "#batch.pyspark_batch.archive_uris = f\"gs://{CODE_BUCKET}/archives/\"\n",
    "\n",
    "# Spark Application Args (optional)\n",
    "batch.pyspark_batch.args = [f\"--pipelineID={PIPELINE_ID}\", \\\n",
    "        f\"--projectID={PROJECT_ID}\", \\\n",
    "        f\"--projectNbr={PROJECT_NBR}\", \n",
    "        f\"--displayPrintStatements={True}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37d173d8-4fe7-4c50-b7e0-875e252d44a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Runtime conf\n",
    "# ....\n",
    "batch.runtime_config.version = f\"{SERVERLESS_SPARK_RUNTIME_VERSION}\"\n",
    "batch.runtime_config.container_image = f\"gcr.io/{PROJECT_ID}/customer_churn_image:{CUSTOM_CONTAINER_IMAGE_TAG}\"\n",
    "batch.runtime_config.properties = {\"spark.jars.packages\": f\"com.google.cloud.spark:spark-bigquery-with-dependencies_{BQ_CONNECTOR_COORDS}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4f08f3a-c548-4724-95f4-d928f10ec4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Env execution conf\n",
    "# Docs: https://cloud.google.com/python/docs/reference/dataproc/latest/google.cloud.dataproc_v1.types.ExecutionConfig\n",
    "batch.environment_config.execution_config.service_account = f\"{UMSA_FQN}\"\n",
    "batch.environment_config.execution_config.subnetwork_uri = f\"projects/{PROJECT_ID}/regions/{GCP_REGION}/subnetworks/{SPARK_SERVERLESS_SUBNET}\"\n",
    "batch.environment_config.execution_config.network_tags = [f\"{NETWORK_TAG}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "079113a0-5f6f-416a-8357-3ef305d9ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Env peripherals conf\n",
    "batch.environment_config.peripherals_config.metastore_service = f\"projects/{PROJECT_ID}/locations/{GCP_REGION}/services/{DPMS_NAME}\"\n",
    "PHS = dataproc.SparkHistoryServerConfig(dataproc_cluster=f\"projects/{PROJECT_ID}/regions/{GCP_REGION}/clusters/{PERSISTENT_HISTORY_SERVER_NM}\")\n",
    "batch.environment_config.peripherals_config.spark_history_server_config = PHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4df462d3-2afb-48e2-a114-0308fbec2352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Create a request\n",
    "\n",
    "request = dataproc.CreateBatchRequest(\n",
    "    parent = f\"projects/{PROJECT_ID}/locations/{GCP_REGION}\",\n",
    "    batch = batch,\n",
    "    batch_id = f\"{BATCH_ID}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83fac812-086b-41f6-a524-5437e9f51bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Submit batch\n",
    "operation = client.create_batch(request=request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c326442-4e31-444c-8a5c-dcb717b100a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for operation to complete...\n"
     ]
    }
   ],
   "source": [
    "print(\"Waiting for operation to complete...\")\n",
    "response = operation.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae86783e-8fa8-4535-a9a9-575734be5058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"projects/gcp-scalable-ml-workshop/locations/us-central1/batches/customer-churn-model-preprocessing-4243706688\"\n",
      "uuid: \"342d5a0e-a66f-449c-b1ef-1c3bf4f25aa1\"\n",
      "create_time {\n",
      "  seconds: 1670025001\n",
      "  nanos: 910665000\n",
      "}\n",
      "pyspark_batch {\n",
      "  main_python_file_uri: \"gs://s8s_code_bucket-569379262211/pyspark/preprocessing.py\"\n",
      "  args: \"--pipelineID=4243706688\"\n",
      "  args: \"--projectID=gcp-scalable-ml-workshop\"\n",
      "  args: \"--projectNbr=569379262211\"\n",
      "  args: \"--displayPrintStatements=True\"\n",
      "  python_file_uris: \"gs://s8s_code_bucket-569379262211/pyspark/common_utils.py\"\n",
      "}\n",
      "runtime_info {\n",
      "  endpoints {\n",
      "    key: \"Spark History Server\"\n",
      "    value: \"https://torvjlsgyjb73jwsyuujcs3pei-dot-us-central1.dataproc.googleusercontent.com/sparkhistory/?eventLogDirFilter=342d5a0e-a66f-449c-b1ef-1c3bf4f25aa1\"\n",
      "  }\n",
      "  output_uri: \"gs://dataproc-staging-us-central1-569379262211-osxvqskd/google-cloud-dataproc-metainfo/7707c3b2-98c7-4d99-aabc-343d3341c871/jobs/srvls-batch-342d5a0e-a66f-449c-b1ef-1c3bf4f25aa1/driveroutput\"\n",
      "}\n",
      "state: SUCCEEDED\n",
      "state_time {\n",
      "  seconds: 1670025385\n",
      "  nanos: 376478000\n",
      "}\n",
      "creator: \"s8s-lab-sa@gcp-scalable-ml-workshop.iam.gserviceaccount.com\"\n",
      "runtime_config {\n",
      "  version: \"1.0.23\"\n",
      "  container_image: \"gcr.io/gcp-scalable-ml-workshop/customer_churn_image:1.0.0\"\n",
      "  properties {\n",
      "    key: \"spark:spark.app.name\"\n",
      "    value: \"projects/gcp-scalable-ml-workshop/locations/us-central1/batches/customer-churn-model-preprocessing-4243706688\"\n",
      "  }\n",
      "  properties {\n",
      "    key: \"spark:spark.driver.cores\"\n",
      "    value: \"4\"\n",
      "  }\n",
      "  properties {\n",
      "    key: \"spark:spark.dynamicAllocation.executorAllocationRatio\"\n",
      "    value: \"0.3\"\n",
      "  }\n",
      "  properties {\n",
      "    key: \"spark:spark.eventLog.dir\"\n",
      "    value: \"gs://s8s-sphs-569379262211/342d5a0e-a66f-449c-b1ef-1c3bf4f25aa1/spark-job-history\"\n",
      "  }\n",
      "  properties {\n",
      "    key: \"spark:spark.executor.cores\"\n",
      "    value: \"4\"\n",
      "  }\n",
      "  properties {\n",
      "    key: \"spark:spark.executor.instances\"\n",
      "    value: \"2\"\n",
      "  }\n",
      "  properties {\n",
      "    key: \"spark:spark.jars.packages\"\n",
      "    value: \"com.google.cloud.spark:spark-bigquery-with-dependencies_2.12:0.25.2\"\n",
      "  }\n",
      "}\n",
      "environment_config {\n",
      "  execution_config {\n",
      "    service_account: \"s8s-lab-sa@gcp-scalable-ml-workshop.iam.gserviceaccount.com\"\n",
      "    subnetwork_uri: \"projects/gcp-scalable-ml-workshop/regions/us-central1/subnetworks/spark-snet\"\n",
      "    network_tags: \"dataproc\"\n",
      "  }\n",
      "  peripherals_config {\n",
      "    metastore_service: \"projects/gcp-scalable-ml-workshop/locations/us-central1/services/s8s-dpms-569379262211\"\n",
      "    spark_history_server_config {\n",
      "      dataproc_cluster: \"projects/gcp-scalable-ml-workshop/regions/us-central1/clusters/s8s-sphs-569379262211\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "operation: \"projects/gcp-scalable-ml-workshop/regions/us-central1/operations/e2fa26df-92f6-49d5-808f-45e089ee3cd5\"\n",
      "state_history {\n",
      "  state: PENDING\n",
      "  state_start_time {\n",
      "    seconds: 1670025001\n",
      "    nanos: 910665000\n",
      "  }\n",
      "}\n",
      "state_history {\n",
      "  state: RUNNING\n",
      "  state_start_time {\n",
      "    seconds: 1670025050\n",
      "    nanos: 481799000\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 11. Handle the response\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
